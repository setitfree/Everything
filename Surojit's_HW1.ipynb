{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Surojit's_HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "r33k0Rv9lm9M",
        "EBJ95eXwlm-i",
        "lg-gMIZTlm_B",
        "vkU3G3UDH6yn",
        "bhy0LnUiIIjE"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7b216d7cae5b405cb689a792215621d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_38e6e8246bd84ee29ceef2a97443eb68",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e69da66704da488d80b9b8eea12f40f5",
              "IPY_MODEL_d00938415e4342778d05f479d2426f6e"
            ]
          }
        },
        "38e6e8246bd84ee29ceef2a97443eb68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e69da66704da488d80b9b8eea12f40f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75ebe7823469471fabc8a50ef237af23",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4da98df78bb44ee9917f9fb63183514"
          }
        },
        "d00938415e4342778d05f479d2426f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf87aac6cb6447cdb9b6fd7c49bf57e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29/29 [21:17&lt;00:00, 44.05s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d45c6ac5eaf4a1f84b69e9fb46b5b32"
          }
        },
        "75ebe7823469471fabc8a50ef237af23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4da98df78bb44ee9917f9fb63183514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf87aac6cb6447cdb9b6fd7c49bf57e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d45c6ac5eaf4a1f84b69e9fb46b5b32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/setitfree/Everything/blob/main/Surojit's_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTAwWJ5Qlmwk"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1nMaBQ7g88duMECw_B4mH8ruxwnIwVzGP\" width=300/> \n",
        "\n",
        "# ML-1: Exploratory Data Analysis, Visualisation & Modeling\n",
        "## Homework 1: Who is the best singer ever?\n",
        "\n",
        "**ML-1 Cohort 1** <br>\n",
        "**Instructor: Dr. Rahul Dave**<br>\n",
        "**Max Score: 100** <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv36XfX2X_Sh"
      },
      "source": [
        "Name of people who have worked on this homework:\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZLSPjS6_8GD"
      },
      "source": [
        "## Table of Contents \r\n",
        "* [HW-1: Who is the best singer ever?](#HW-1:-Who-is-the-best-singer-ever?)\r\n",
        "  * [Instructions](##Instructions)\r\n",
        "  * [Learning Goals](##Learning-Goals)\r\n",
        "  * [Q1: Scrape and Parse Wikipedia for Billboard Top 100](##Q1:-Scrape-and-Parse-Wikipedia-for-Billboard-Top-100)\r\n",
        "    * [1.1 Scrape and Parse the Billboard Wikipedia's page for 1970](###1.1-Scrape-and-Parse-the-Billboard-Wikipedia's-page-for-1970)\r\n",
        "    * [1.2 Scrape Billboard Wikipedia's pages from 1992 to 2020](###1.2-Scrape-Billboard-Wikipedia's-pages-from-1992-to-2020)\r\n",
        "    * [1.3 Parse the data](###1.3-Parse-the-data)\r\n",
        "  * [Q2: Construct a year-song-singer dataframe](##Q2:-Construct-a-year-song-singer-dataframe)\r\n",
        "  * [Q3: Scrape and Parse Wikipedia for Information about Artists and Bands](##Q3:-Scrape-and-Parse-Wikipedia-for-Information-about-Artists-and-Bands)\r\n",
        "    * [3.1 Scrape the artist's Wikipedia webpages](###3.1-Scrape-the-artist's-Wikipedia-webpages)\r\n",
        "    * [3.2 Parse the data](###3.2-Parse-the-data)\r\n",
        "  * [Q4: Merging Artist's and Song dataframes](##Q4:-Merging-Artist's-and-Song-dataframes)\r\n",
        "  * [Q5: Pandas and Relational databases](##Q5:-Pandas-and-Relational-databases)\r\n",
        "    * [5.1 Populating the database](###5.1-Populating-the-database)\r\n",
        "    * [5.2 Performing operations on the database](####5.2-Performing-operations-on-the-database)\r\n",
        "      * [5.2.1 Select all singers below the age of 20 whos Zodiac Sign is Scorpio!](####5.2.1-Select-all-singers-below-the-age-of-20-whos-Zodiac-Sign-is-Scorpio!)\r\n",
        "      * [5.2.2 Find the most popular artists with most appearances in Billboard Top 10](####5.2.2-Find-the-most-popular-artists-with-most-appearances-in-Billboard-Top-10)\r\n",
        "      * [5.2.3 Select all songs with ranking less than 6 and order the rows by artist name](####5.2.3-Select-all-songs-with-ranking-less-than-6-and-order-the-rows-by-artist-name)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vym0YdCZYCeS"
      },
      "source": [
        "## Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMkXfrJWYDtC"
      },
      "source": [
        "- This homework should be submitted in pairs.\r\n",
        "\r\n",
        "- Ensure you and your partner together have submitted the homework only once. Multiple submissions of the same work will be penalised and will cost you 2 points.\r\n",
        "\r\n",
        "- Please restart the kernel and run the entire notebook again before you submit.\r\n",
        "\r\n",
        "- Running cells out of order is a common pitfall in Notebooks. To make sure your code works restart the kernel and run the whole notebook again before you submit. \r\n",
        "\r\n",
        "- To work on the homework, you will first need to fork the repository into your GitHub account and clone it to work on it on your local computer. To submit your homework, push your homework into the same GitHub and upload the link on edStem.\r\n",
        "\r\n",
        "- Submit the homework well before the given deadline. Submissions after the deadline will not be graded.\r\n",
        "\r\n",
        "- We have tried to include all the libraries you may need to do the assignment in the imports statement at the top of this notebook. We strongly suggest that you use those and not others as we may not be familiar with them.\r\n",
        "\r\n",
        "- Comment your code well. This would help the graders in case there is any issue with the notebook while running. It is important to remember that the graders will not troubleshoot your code. \r\n",
        "\r\n",
        "- Please use .head() when viewing data. Do not submit a notebook that is **excessively long**. \r\n",
        "\r\n",
        "- In questions that require code to answer, such as \"calculate the $R^2$\", do not just output the value from a cell. Write a `print()` function that includes a reference to the calculated value, **not hardcoded**. For example: \r\n",
        "```\r\n",
        "print(f'The R^2 is {R:.4f}')\r\n",
        "```\r\n",
        "- Your plots should include clear labels for the $x$ and $y$ axes as well as a descriptive title (\"MSE plot\" is not a descriptive title; \"95 % confidence interval of coefficients of polynomial degree 5\" is).\r\n",
        "\r\n",
        "- **Ensure you make appropriate plots for all the questions it is applicable to, regardless of it being explicitly asked for.**\r\n",
        "\r\n",
        "<hr style=\"height:2pt\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zv8VWFhP_32L"
      },
      "source": [
        "## Learning Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmqsUs9Olm18"
      },
      "source": [
        "Billboard Magazine puts out a top 100 list of \"singles\" every **year**. \n",
        "In the next two homeworks, you will scrape Wikipedia to try to understand how the public's taste in music has evolved. You will do this by learning about the best singers and groups from each year as determined by the Billboard top 100 charts.\n",
        "\n",
        "This homework consists of five main parts:\n",
        "\n",
        "1. Scraping and Parsing [Wikipedia's Billboard Top 100 singles](https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_2020) list for every year <br>\n",
        "2. Constructing a year-song-singer dataframe from the scraped data\n",
        "3. Scraping and Parsing Wikipedia's information about the Artists from these Songs \n",
        "4. Merging in both the above dataframes \n",
        "5. Using a Relational Database to perform SQL queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUHkcabZlm2Q"
      },
      "source": [
        "This homework will help develop your skills in:\n",
        "\n",
        "- Web page scraping\n",
        "- Data cleaning and manipulation\n",
        "- Pandas and SQL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW_1toqQlm21"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deZ11vb4lm3e",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "#Import libraries\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "import re\n",
        "import requests"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4necLqglm3p"
      },
      "source": [
        "## Q1: Scrape and Parse Wikipedia for Billboard Top 100\n",
        "#### [20 Points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_ajVEDhlm3t"
      },
      "source": [
        "In this first question you will scrape wikipedia for Billboard's top 100.\r\n",
        "\r\n",
        "We will be using [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/) to transform HTML content into Python data structures. There are other libraries such as [PyQuery](https://pythonhosted.org/pyquery/) (for people who have used [jQuery](https://jquery.com/) that can also be used)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4bbGU0glm3_",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "#Import Beautiful Soup\r\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54udQNZ-lm4F"
      },
      "source": [
        "### 1.1 Scrape and Parse the Billboard Wikipedia's page for 1970"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtxCwDBqlm4f"
      },
      "source": [
        "Use python's `requests` module to obtain (GET) the web page at http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1970. \n",
        "From this web page, extract the top 100 singles and their rankings. \n",
        "\n",
        "\n",
        "To do this, create a list of dictionaries, 100 of them to be precise, with the following entries: `{'url': '/wiki/Sugarloaf_(band)', 'ranking': 30, 'band_singer': 'Sugarloaf', 'title': 'Green-Eyed Lady'}`. \n",
        "\n",
        "Name this list of dictionaries `songs`.\n",
        "\n",
        "\n",
        "Here, `url` should be the link for the singer or band (observe that on the web page, there is a link for every song and artist), `ranking` is the ranking of the song, `band_singer` should be the name of the artist(s) and `title` should be the title of the song.\n",
        "\n",
        "\n",
        "We are extracting the `url` of the artist(s) to use at a later stage in the homework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1srjTzGlm4t"
      },
      "source": [
        "*Hint:*\n",
        "While parsing the HTML, look for the HTML _tr_ (table row) element, but only the one that has a CSS class of _wikitable_. If you look at the page source, you'll see a construct like __class=wikitable__ on the table as seen below:\n",
        "\n",
        "\n",
        "\n",
        "![Wikipage](\n",
        "https://drive.google.com/uc?export=view&id=1ntewsqyZVH6_RETloTQgrWIyQJAa_02D) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teLpU_AZlm4o",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "#Get the webpage\r\n",
        "t1970=requests.get(\"http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1992\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p7QBSodlm41",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "#Parsing the webpage\n",
        "\n",
        "#your code here\n",
        "soup=BeautifulSoup(t1970.text,'html.parser')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8PutYPDXJOF"
      },
      "source": [
        "songs=[]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4oe4f0gw5Mc"
      },
      "source": [
        "rows=soup.find('table',attrs={'class':'wikitable'}).findChildren('tbody')[0].findChildren('tr')\r\n",
        "for i in range(1,len(rows)):\r\n",
        "  row=rows[i]\r\n",
        "  songs.append({'titletext':row.findChildren('td')[-2].text.strip().split('/'),\r\n",
        "                'song_url':[link['href'] for link in row.findChildren('td')[-2].findChildren('a')],\r\n",
        "                'artist_url':[a_link['href'] for a_link in row.findChildren('td')[-1].findChildren('a')],\r\n",
        "                'ranking':row.findChildren()[0].text,\r\n",
        "                'artist':row.findChildren('td')[-1].text.strip().split('/')})"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6wf4pqKlm48"
      },
      "source": [
        "### 1.2 Scrape Billboard Wikipedia's pages from 1992 to 2020 \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Spk5hLjlm4_"
      },
      "source": [
        "By visiting urls similar to the one for 1970, we can obtain the billboard top 100 for the years 1992 to 2020. \r\n",
        "\r\n",
        "Store the text from your `requests` in a dictionary called `yearstext`. \r\n",
        "This dictionary should have as its keys the years (as integers from 1992 to 2020). The values corresponding to these keys should be the html text downloaded from Wikipedia.<br>\r\n",
        "So, each entry in `yearstext` will look something like this:\r\n",
        "\r\n",
        "![yearstext](https://drive.google.com/uc?export=view&id=16LNIyznVnAY-N5EN6lsSB9505fXG1-zK)\r\n",
        "\r\n",
        "where the key is 1992 and the value is the HTML at http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1992."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G3NooTslm5H"
      },
      "source": [
        "*Hint*:\n",
        "Put your requests.get() in a `for` loop and keep appending the text from your requests into the dictionary. Use the `time.sleep` function to wait one second between requests, you do not want Wikipedia to think you are a marauding bot attempting to mount a denial-of-service attack."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTfPHuolYZQ9"
      },
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmWtNV42lm5Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "7b216d7cae5b405cb689a792215621d6",
            "38e6e8246bd84ee29ceef2a97443eb68",
            "e69da66704da488d80b9b8eea12f40f5",
            "d00938415e4342778d05f479d2426f6e",
            "75ebe7823469471fabc8a50ef237af23",
            "a4da98df78bb44ee9917f9fb63183514",
            "cf87aac6cb6447cdb9b6fd7c49bf57e9",
            "6d45c6ac5eaf4a1f84b69e9fb46b5b32"
          ]
        },
        "outputId": "42d7c22c-48d4-4291-ad8e-010a5fcdf3d3"
      },
      "source": [
        "#your code here\n",
        "URLSTART=\"http://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_\"\n",
        "yearstext={}\n",
        "for i in tqdm(range(1992,2021)):\n",
        "  url=URLSTART+str(i)\n",
        "  data=requests.get(url).text\n",
        "  yearstext[i]=data\n",
        "  time.sleep(2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b216d7cae5b405cb689a792215621d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agIKGBkVlm6G"
      },
      "source": [
        "### 1.3 Parse the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ_l5dn-lm6K"
      },
      "source": [
        "Now, write a function `parse_year(year, yeartextdict)` that returns a dictionary `yearinfo`.\n",
        "Here `year` should be the integer value of the year, and `yeartextdict` should be the HTML text for the corresponding webpage. \n",
        "This function should return a dictionary of the following form:\n",
        "\n",
        "```\n",
        "{'ranking': 32,\n",
        " 'song': ['Hot Boyz (song)'],\n",
        " 'songurl': ['/wiki/Hot_Boyz_(song)'],\n",
        " 'titletext': '\"Hot Boyz\"',\n",
        " 'band_singer': ['Missy Elliott', 'Nas', 'Eve (rapper)', 'Q-Tip (musician)'],\n",
        " 'url': ['/wiki/Missy_Elliott',\n",
        "  '/wiki/Nas',\n",
        "  '/wiki/Eve_(rapper)',\n",
        "  '/wiki/Q-Tip_(musician)']}\n",
        "```\n",
        "Notice that the `titletext` is the contents of the table cell, and retains the quotes that wikipedia puts on the single.\n",
        "\n",
        "Here are some issues that you will need to take care of:\n",
        "\n",
        "1.   The example shown above has several artists for a single song. In this case, the `band_singer` and `url` would be a list of items.\n",
        "\n",
        "2.   Some singles might even have multiple songs because of the way the industry works:\n",
        "```\n",
        "{'ranking': 98,\n",
        " 'song': [\"You're Makin' Me High\", 'Let It Flow (song)'],\n",
        " 'songurl': ['/wiki/You%27re_Makin%27_Me_High', '/wiki/Let_It_Flow_(song)'],\n",
        " 'titletext': '\"You\\'re Makin\\' Me High\" / \"Let It Flow\"',\n",
        " 'band_singer': ['Toni Braxton'],\n",
        " 'url': ['/wiki/Toni_Braxton']}\n",
        "```\n",
        "(See 1997 for an example)\n",
        "\n",
        "3. Some songs don't have a URL. In this case, assume there is one song in the single, set `songurl` to [`None`] and the song name to the contents of the table cell with the quotes stripped:\n",
        "```\n",
        "{'ranking': 45,\n",
        "  'song': ['Say It'],\n",
        "  'songurl': [None],\n",
        "  'titletext': '\"Say It\"',\n",
        "  'band_singer': ['Voices of Theory'],\n",
        "  'url': ['/wiki/Voices_of_Theory']}\n",
        "```\n",
        "(See 1998 for an example)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXpy7iA0lm6h",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "\"\"\"\n",
        "Function\n",
        "--------\n",
        "parse_year\n",
        "\n",
        "Inputs\n",
        "------\n",
        "year: the year you want the singles for\n",
        "ytextdixt: a dictionary with keys as integer years and values the downloaded web pages \n",
        "    from wikipedia for that year.\n",
        "   \n",
        "Returns\n",
        "-------\n",
        "\n",
        "a list of dictionaries, each of which corresponds to a single and has the\n",
        "following data:\n",
        "\n",
        "Eg:\n",
        "\n",
        "{'band_singer': ['Brandy', 'Monica'],\n",
        "  'ranking': 2,\n",
        "  'song': ['The Boy Is Mine'],\n",
        "  'songurl': ['/wiki/The_Boy_Is_Mine_(song)'],\n",
        "  'titletext': '\" The Boy Is Mine \"',\n",
        "  'url': ['/wiki/Brandy_Norwood', '/wiki/Monica_(entertainer)']}\n",
        "  \n",
        "A dictionary with the following data:\n",
        "    band_singer: a list of bands/singers who made this single\n",
        "    song: a list of the titles of songs on this single\n",
        "    songurl: a list of the same size as song which has urls for the songs on the single \n",
        "        (see point 3 above)\n",
        "    ranking: ranking of the single\n",
        "    titletext: the contents of the table cell\n",
        "    band_singer: a list of bands or singers on this single\n",
        "    url: a list of wikipedia singer/band urls on this single: only put in the part \n",
        "        of the url from /wiki onwards\n",
        "    \n",
        "\"\"\"\n",
        "#your code here\n",
        "def parse_year(year,yeartextdict):\n",
        "  yeardata=[]\n",
        "  soup=BeautifulSoup(yeartextdict[year])\n",
        "  rows=soup.find('table',attrs={'class':'wikitable'}).findChildren('tbody')[0].findChildren('tr')\n",
        "  for i in range(1,len(rows)):\n",
        "    row=rows[i]\n",
        "    yeardata.append({'song':row.findChildren('td')[-2].text.strip().split('/'),\n",
        "                     'titletext':row.findChildren('td')[-2].text.strip(),\n",
        "                  'songurl':[link['href'] for link in row.findChildren('td')[-2].findChildren('a')],\n",
        "                  'url':[a_link['href'] for a_link in row.findChildren('td')[-1].findChildren('a')],\n",
        "                  'ranking':int(row.findChildren()[0].text.strip()),\n",
        "                  'band_singer':row.findChildren('td')[-1].text.strip().split('/')})\n",
        "  return yeardata"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OJdGaTrlm6t",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "#your code here\r\n",
        "yearinfo= {}\r\n",
        "for i in range(1992,2021):\r\n",
        "  yearinfo[i]=parse_year(i,yearstext)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "044UilQrsU_x"
      },
      "source": [
        "Save this dictionary as a json file so you do not need to run it over and over again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY78wI-GiI6E",
        "outputId": "f310d93a-f4c0-469f-9f38-de9c88c0203c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyZCQ0Fmlm60",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "#Store the dictionary and delete the variable\n",
        "fd = open(\"/content/drive/MyDrive/Colab Notebooks/yearinfo.json\",\"w\")\n",
        "json.dump(yearinfo, fd)\n",
        "fd.close()\n",
        "del yearinfo"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOuXxgltlm68",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "#Load the dictionary back to the same variable\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/yearinfo.json\", \"r\") as fd:\n",
        "    yearinfo = json.load(fd)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vOm9xzPlx__"
      },
      "source": [
        "yearinfo['1992']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZFmw3xJt6mS"
      },
      "source": [
        "def functions(i, yearstext):\n",
        "  yearsinfo = parse_year(i, yearstext)\n",
        "  fd = open('yearsinfo.json', 'w')\n",
        "  json.dump(yearsinfo, fd)\n",
        "  fd.close()\n",
        "  del yearsinfo\n",
        "  with open('yearinfo.json', 'r') as fd:\n",
        "    yearinfo = json.load(fd)\n",
        "  return yearinfo"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd_0dzuslm7B"
      },
      "source": [
        "## Q2: Construct a year-song-singer dataframe \n",
        "#### [20 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGDX83Xblm7E"
      },
      "source": [
        "Now, let's construct a dataframe from the dictionary created in the previous section `yearinfo`. \n",
        "Name this dataframe `flatframe`.\n",
        "\n",
        "Keep in mind, in the data structure we have so far, a given key can have a list of values with multiple entries. Also, our data is grouped by year. So we need a way to flatten this data into a format that will create a useful DataFrame. \n",
        "\n",
        "An easy way to do this is to use the pandas `concat` function.\n",
        "\n",
        "Your final dataframe `flatframe` should look something like this:\n",
        "![flatframexample](https://drive.google.com/uc?export=view&id=12hlpB-zRGJh6JYCTcMoTzumKSyXgfoiY)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GOsaIDh0Uvt"
      },
      "source": [
        "flatframe = pd.DataFrame()\n",
        "df = pd.DataFrame.from_dict(yearinfo)\n",
        "df1 = df.values.flatten()\n",
        "df_new =pd.DataFrame(df1)\n",
        "df_new['band_singer'] #row.findChildren('td')[-1].text.strip().split('/')})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Tk6XgIslm7I"
      },
      "source": [
        "#your code here \n",
        "df = pd.DataFrame.from_dict(functions(1992, yearstext))\n",
        "flatframe = pd.DataFrame()\n",
        "for i in range(1992,2020):\n",
        "  df1 = pd.DataFrame.from_dict(functions(1992, yearstext))\n",
        "  flatframe = pd.concat([df,df1])\n",
        "  df = flatframe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClCy4yynklvW"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCPYpq8Ltu72"
      },
      "source": [
        "Check your dataframes data types and convert them to the correct data types if needed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYnRAOZilm7d",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "flatframe.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wftoYesOSXL5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nSngWg6WJqM"
      },
      "source": [
        "We use this dataframe in Homework 2, so store this dataframe so you won't need to run this again!\r\n",
        "\r\n",
        "The easiest way is to pickle it using to_pickle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5937BG6tWGph"
      },
      "source": [
        "#Store the dataframe and delete the variable\r\n",
        "flatframe.to_pickle('/content/flatframedf')\r\n",
        "del flatframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLkQcqmOuFR9"
      },
      "source": [
        "#Loading in the dataframe\r\n",
        "flatframe = pd.read_pickle('/content/flatframedf')\r\n",
        "flatframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc8dNE4nlm7t"
      },
      "source": [
        "## Q3: Scrape and Parse Wikipedia for Information about Artists and Bands \n",
        "#### [25 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACpaxf42lm7w"
      },
      "source": [
        "Now, we need to fetch information about the singers or bands for all the songs in a list of years."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEWBhVhQlm74"
      },
      "source": [
        "### 3.1 Scrape the artist's Wikipedia webpages "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddXAyi5Vlm77"
      },
      "source": [
        "Since we have hundreds of artists webpages to scrape, we have created a function which implements caching in order to speed up this process.\r\n",
        "\r\n",
        "The cache object `urlcache` that will avoid redundant HTTP requests (e.g. an artist might have multiple singles on a single year, or be on the list over a span of years). Remember that this function is designed to be used in a loop over years, and then a loop over songs per year. Since network requests are relatively slow, if we have already requested for a singer or band's wikipedia page, caching the results is a smart thing to do.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "Notice that we have wrapped the call in _an exception block_. If the request gets an HTTP code different from 200, the cells for that URL will have a value of 1; and if the request completely fails (e.g. no network connection) the cell will have a value of 2. This will allow you to analyse the failed requests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLIr5RLOlm8C",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "urlcache={}\n",
        "def get_page(url):\n",
        "    if (url not in urlcache) or (urlcache[url]==1) or (urlcache[url]==2):\n",
        "        time.sleep(1)\n",
        "        try:\n",
        "            r = requests.get(\"http://en.wikipedia.org%s\" % url)\n",
        "            if r.status_code == 200:\n",
        "                urlcache[url] = r.text\n",
        "            else:\n",
        "                urlcache[url] = 1\n",
        "        except:\n",
        "            urlcache[url] = 2\n",
        "    return urlcache[url]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KvxocZMlm8F"
      },
      "source": [
        "Before we apply our function to the dataframe, let us sort `flatframe` by year. This will ensure that we will hit the cache most as singers who show up repeatedly in the rankings will have their information already pulled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slMlUwrXlm8K",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "flatframe=flatframe.sort_values('year')\n",
        "flatframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jGHEg1IDlm8O",
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true
      },
      "source": [
        "# Here we are populating the url cache\n",
        "#Note that this function will take around 20 minutes to run as we are requestinf for several pages\n",
        "#This function is designed to be run again and again: it just tries to make sure that there are no unresolved pages left. \n",
        "flatframe[\"url\"].apply(get_page)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtH5ch-Jlm8X",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "#Let us make sure that there are no unresolved pages\n",
        "#The sum below should be 0, and the boolean True. If that is not the case, run the above cell again until you get a sum of 0 and a boolean True\n",
        "print (np.sum([(urlcache[k]==1) or (urlcache[k]==2) and isinstance(k,str) for k in urlcache]))\n",
        "print (len(flatframe.url.unique())==len(urlcache))#we got all of the urls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-g3mOWrlm8c",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "#Let's save the `urlcache` and remove the old object. \n",
        "keys_values = urlcache.items()\n",
        "urlcache = {str(key): str(value) for key, value in keys_values}\n",
        "with open(\"artistinfo.json\",\"w\") as fd:\n",
        "    json.dump(urlcache, fd)\n",
        "del urlcache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctcBqdEPlm8f",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "with open(\"/content/gdrive/MyDrive/DS-1 /HW-1/artistinfo.json\") as json_file:\n",
        "    urlcache = json.load(json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_G84LnUlm8p"
      },
      "source": [
        "### 3.2 Parse the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urcGynNplm8r"
      },
      "source": [
        "Now, we need to extract the following information from each page. Write a function `singer_band_info(url, page_text)` that returns a dictionary. \n",
        "\n",
        "Here `url` should be the path the url corresponding to the singer's Wikipedia page (same as the previous dataframe `flatframe`), and page_text should be the HTML text for the corresponding artist's webpage. \n",
        "\n",
        "This function should return a dictionary which contains the following information:\n",
        "\n",
        "1. The genres of the band or singer. These genres should be urls, to ensure their uniqueness. Create a list, `genres`, of these urls. If there are no genres, use `['NA']`.\n",
        "\n",
        "2. If the page has the text \"Born\", extract the element with the class `.bday`. If there is no \"Born\", store `False`. Store either of these into the variable `born`. \n",
        "\n",
        "3. If the text \"Years active\" is found, but there is no birthday, assume a band. Store the years active into the variable `ya`, or `False` if the text is not found. \n",
        "\n",
        "The information can be found below the artists image on each such wikipedia page, as the example here shows:\n",
        "\n",
        "\n",
        "![EdSheeran](https://drive.google.com/uc?export=view&id=1NJi2C-Gi5HPziuPxefNcjj5i4-04kuQ-)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmsucMYj31Ft"
      },
      "source": [
        "The dictionary returned should be of the form:\r\n",
        "```\r\n",
        "{ 'url': '/wiki/Boyz_II_Men', \r\n",
        "'genres': ['/wiki/Contemporary_R%26B_music', '/wiki/Soul_music', '/wiki/New_jack_swing'], \r\n",
        "'born': None, \r\n",
        "'ya': '1987â€“present'}\r\n",
        "```\r\n",
        "\r\n",
        "Wikipedia has changed it's format along the years! So observing one artist's webpage and building your function based on it will probably give you tons of errors. \r\n",
        "\r\n",
        "Here are a few issues to remember while parsing:\r\n",
        "\r\n",
        "1.   There are several artists that take a sabbatical between their active years (https://en.wikipedia.org/wiki/Tony!_Toni!_Ton%C3%A9!). To get the right data, write a function to calculate the longest period of time they were active and consider that as your variable `years active`. In the example give, this would be 2003â€“present.\r\n",
        "2.   Birthday's are given in different formats for different pages. For example - https://en.wikipedia.org/wiki/Sir_Mix-a-Lot and https://en.wikipedia.org/wiki/Ed_Sheeran have different formats. To ensure that you get the right day, look for the 'span' tag with a 'bday' tag and ensure that there are no paranthesis around the extracted text.\r\n",
        "3. Year's active are also given in different formats. For example - https://en.wikipedia.org/wiki/Boyz_II_Men and https://en.wikipedia.org/wiki/Ed_Sheeran are different. You could use regex (\"[0-9]{4}[â€“][0-9]{4}\" and \"[0-9]{4}[â€“][0-9]{4}\") to ensure you are getting the right years.<br> Report the edge cases found and why the Regex expression takes care of all these edge cases.\r\n",
        "\r\n",
        "Definitely do look at your outputs as you are parsing as it can identify several edge cases you have not considered in your code.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wepOCDnV2H3p"
      },
      "source": [
        "Before parsing, it is important to note that Wikipedia has defined the same genre in a few different ways. Our parsing code will pick these up as different and new as they all differ with the alphabet case or an underscore instead of a hyphen.\r\n",
        "\r\n",
        "We have defined a function to ensure that we have the correct representation of the number of artists in a particular genre. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTSJHvJF3pxu"
      },
      "source": [
        "genres_duplicates={'/wiki/Adult_Contemporary_music':'/wiki/Adult_contemporary','/wiki/Adult_contemporary_music':'/wiki/Adult_contemporary',\r\n",
        "'/wiki/Afrobeat':'/wiki/Afrobeats',\r\n",
        "'/wiki/Alternative_rock':'/wiki/Alternative_Rock',\r\n",
        "'/wiki/Avant-garde':'/wiki/Avant-garde_music',\r\n",
        "'/wiki/Blues':'/wiki/Blues_music',\r\n",
        "'/wiki/Comedy_hip-hop':'/wiki/Comedy_hip_hop',\r\n",
        "'/wiki/Contemporary_R%26B':'/wiki/Contemporary_R%26B_music',\r\n",
        "'/wiki/Contemporary_folk':'/wiki/Contemporary_folk_music',\r\n",
        "'/wiki/Country_Folk':'/wiki/Country_folk',\r\n",
        "'/wiki/Dance_pop':'/wiki/Dance-pop',\r\n",
        "'/wiki/East_Coast_hip_hop':'/wiki/East_coast_hip_hop',\r\n",
        "'/wiki/Electronic_Dance_Music':'/wiki/Electronic_dance_music',\r\n",
        "'/wiki/Electronica':'/wiki/Electronica_music',\r\n",
        "'/wiki/Emo':'/wiki/Emo_music',\r\n",
        "'/wiki/Electropop':'/wiki/Electro-pop',\r\n",
        "'/wiki/Folk-pop':'/wiki/Folk_pop',\r\n",
        "'/wiki/Funk':'/wiki/Funk_music',\r\n",
        "'/wiki/Grime_(music_genre)':'/wiki/Grime_music',\r\n",
        "'/wiki/Gangsta_Rap':'/wiki/Gangsta_rap',\r\n",
        "'/wiki/Hip_Hop_music': '/wiki/Hip_hop','/wiki/Hip_hop_music':'/wiki/Hip_hop',\r\n",
        "'/wiki/Hyphy':'/wiki/Hyphy_music',\r\n",
        "'/wiki/Latin_music':'/wiki/Latin_music_(genre)',\r\n",
        "'/wiki/West_Coast_hip_hop':'/wiki/West_coast_hip_hop',\r\n",
        "'/wiki/Southern_Hip_Hop':'/wiki/Southern_hip_hop',\r\n",
        "'/wiki/Ska':'/wiki/Ska_music',\r\n",
        "'/wiki/Pop-rock':'/wiki/Pop_rock',\r\n",
        "'/wiki/Pop_Music':'/wiki/Pop_music',\r\n",
        "'/wiki/Nu_metal':'/wiki/Nu_metal_music'}\r\n",
        "\r\n",
        "def genre_duplicates(genres):\r\n",
        "    for i in range(len(genres)):\r\n",
        "        if genres[i] in genres_duplicates.keys():\r\n",
        "            genres[i]=genres_duplicates[genres[i]]\r\n",
        "    return genres "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w955jc_x7oSS"
      },
      "source": [
        "Define a function to calculate the longest active years"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCiUaa3t1mdM"
      },
      "source": [
        "#your code here \r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C30IKrh_lm89"
      },
      "source": [
        "Please write the function `singer_band_info` according to the following specification:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "144RCE17lm9C",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "\"\"\"\n",
        "Function\n",
        "--------\n",
        "singer_band_info\n",
        "\n",
        "Inputs\n",
        "------\n",
        "url: the url\n",
        "page_text: the text associated with the url\n",
        "   \n",
        "Returns\n",
        "-------\n",
        "A dictionary with the following data:\n",
        "    url: copy the input argument url into this value\n",
        "    genres: the genres that the band or singer works in\n",
        "    born: the artist's birthday\n",
        "    ya: years active variable\n",
        "\n",
        "Notes\n",
        "-----\n",
        "See description above. Also note that some of the genres urls might require a \n",
        "bit of care and special handling.\n",
        "\"\"\"\n",
        "\n",
        "#your code here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O42ei5C9lm9Q"
      },
      "source": [
        "Let's iterate over the items in the singer-group dictionary cache `urlcache`, run the above function, and create a list.\r\n",
        "\r\n",
        "Each element in this list is the dictionary that the function `singer_band_info` returns. \r\n",
        "\r\n",
        "The list should look something like this:\r\n",
        "```\r\n",
        "  'genres': ['/wiki/Contemporary_R%26B_music',\r\n",
        "   '/wiki/Soul_music',\r\n",
        "   '/wiki/New_jack_swing'],\r\n",
        "  'url': '/wiki/Boyz_II_Men',\r\n",
        "  'ya': '1987â€“present'},\r\n",
        " {'born': None,\r\n",
        "  'genres': ['/wiki/Pop_music',\r\n",
        "   '/wiki/Electronica_music',\r\n",
        "   '/wiki/Dance_music',\r\n",
        "   '/wiki/Rave_music',\r\n",
        "   '/wiki/House_music'],\r\n",
        "  'url': '/wiki/KWS_(band)',\r\n",
        "  'ya': '1991â€“1994'},\r\n",
        " ... and so on]\r\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYZCt97qlm9J",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "#your code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN0xOthZUsaY"
      },
      "source": [
        "#Store the list and delete the variable\r\n",
        "with open(\"singer_band_info_list.json\",\"w\") as fd:\r\n",
        "    json.dump(singer_band_info_list, fd)\r\n",
        "del singer_band_info_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kze3PT80yvuT"
      },
      "source": [
        "#Load the list into a variable\r\n",
        "with open(\"/content/gdrive/MyDrive/DS-1 /HW-1/singer_band_info.json\") as json_file:\r\n",
        "    singer_band_info_list = json.load(json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFBbluyq_xUg"
      },
      "source": [
        "Create a dataframe from the list `singer_band_info_list`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2Jq1tIhlm9X",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "#your code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r33k0Rv9lm9M"
      },
      "source": [
        "## Q4: Merging Artist's and Song dataframes\n",
        "#### [15 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK8nFxMblm9d"
      },
      "source": [
        "Now, merge the artist/song data frames into one large dataframe. Note that this has an effect of imputing to a song **all the genres** that the artist is active in. We know that this is not true, but it is the simplest assumption we can make, and is probably good for most artists. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXmWArJllm9h",
        "jupyter": {
          "outputs_hidden": false
        },
        "scrolled": true
      },
      "source": [
        "#your code here\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWlzfSxelm9y"
      },
      "source": [
        "Update the dataframe by adding a column for each genre with 1-0 encoding for each row. This means, we want columns like \"/wiki/Alternative_Rock\", \"/wiki/Acid_jazz\", where if an artist is in that genre, the dataframe cell has a 1. Otherwise, it has a 0.\n",
        "\n",
        "Remember that an artist/band can be in multiple genres, and must have a 1 for each column corresponding to these genres, and 0 otherwise.\n",
        "\n",
        "This will widen the dataframe by the total number of genres that we have. The expanded part will look a bit like this:\n",
        "\n",
        "![largedfexample](https://drive.google.com/uc?export=view&id=1YgIVsyjWLXIAipI5dF2H4fvAmQodpE8L)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh1QgHeTlm92",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "#your code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTAqUUSFTOlg"
      },
      "source": [
        "Ensure the data types of the dataframe is correct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUFfkyyKusfS"
      },
      "source": [
        "#your code here\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M9HSYg_W-1G"
      },
      "source": [
        "#Store the dataframe to use in HW-2 \r\n",
        "largedf.to_pickle('/content/largedf')\r\n",
        "del largedf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzDU-GJ-BjtJ"
      },
      "source": [
        "#Loading in dataframe\r\n",
        "largedf = pd.read_pickle('/content/gdrive/MyDrive/DS-1 /HW-1/largedf')\r\n",
        "largedf.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7mvhskZlm-W"
      },
      "source": [
        "## Q5: Pandas and Relational databases\n",
        "#### [20 points]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBJ95eXwlm-i"
      },
      "source": [
        "### 5.1 Populating the database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTdi6of6lm-n"
      },
      "source": [
        "We use sqlite3 here. There is an even higher level API available, called SQLAlchemy.  However SQLite is built into Python and also has a command line tool and sqlite browser that you can install. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA6D06EwFiqF"
      },
      "source": [
        "import sqlite3 as sql"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMIIU4Q8FmkE"
      },
      "source": [
        "Let us start by creating our schema to set the type of each column in our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaU9NgFxKdL3"
      },
      "source": [
        "#your code here \r\n",
        "#ourschema=' '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNaaiKo4FKvi"
      },
      "source": [
        "Next, create a connection object which will connect us to the database and will let us execute the SQL statements. \r\n",
        "Create an object of the cursor using the connection object and execute our schema. \r\n",
        "Finally, use the `to_sql` function and convert our large expanded dataframe from the last section to a table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLOXLo2VHS52"
      },
      "source": [
        "#your code here\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg-gMIZTlm_B"
      },
      "source": [
        "### 5.2 Performing operations on the database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddf94jAUOjJf"
      },
      "source": [
        "Answer the following questions by writing SQL statements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ptRH0PRHq10"
      },
      "source": [
        "#### 5.2.1 Select all singers below the age of 20 whos Zodiac Sign is Scorpio! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyuqKAuAF5ZQ"
      },
      "source": [
        "#your code here\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkU3G3UDH6yn"
      },
      "source": [
        "#### 5.2.2 Find the most popular artists with most appearances in Billboard Top 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh74afqzGjXb"
      },
      "source": [
        "#your code here\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhy0LnUiIIjE"
      },
      "source": [
        "#### 5.2.3 Select all songs with ranking less than 6 and order the rows by artist name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MolYEOfIHTZ"
      },
      "source": [
        "#your code here \r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD8PC24kNbVI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}